# Deep Learning Notes ðŸ§ 

This repo is a collection of deep learning concepts I implement and revisit.  
Since we keep forgetting things, this acts as my quick **revision hub** with links and code.  

---

## Architectures
- **CNN** â†’ [Guide](https://medium.com/thedeephub/convolutional-neural-networks-a-comprehensive-guide-5cc0b5eae175)  
- **ResNet** â†’ [Understanding Residual Networks](https://medium.com/swlh/resnet-a-simple-understanding-of-the-residual-networks-bfd8a1b4a447)  
- **DenseNet** â†’ [Complete Guide](https://medium.com/@alejandro.itoaramendia/densenet-a-complete-guide-84fedef21dcc)  
- **EfficientNet** â†’ [Smarter, Not Just Bigger](https://medium.com/@kdk199604/efficientnet-smarter-not-just-bigger-neural-networks-94db3e2f8699)  
- **VGGNet** â†’ [Architecture Explained](https://medium.com/@siddheshb008/vgg-net-architecture-explained-71179310050f)
- **Convnext-Vision Transformer** ->[Convnets deepdive](https://medium.com/augmented-startups/convnext-the-return-of-convolution-networks-e70cbe8dabcc)

---

## Loss Functions & Optimizers
- **Focal Loss** â†’ [Quick Read](https://medium.com/visionwizard/understanding-focal-loss-a-quick-read-b914422913e7)  
- **Loss Functions in DL** â†’ [Overview](https://medium.com/@ibtedaazeem/loss-functions-in-deep-learning-e4bd353ea08a)  
- **Optimizers & Loss Functions Together** â†’ [Explained](https://medium.com/analytics-vidhya/optimizer-loss-functions-in-neural-network-2520c244cc22)
  

---

## Why this repo?
- To **revise DL architectures & concepts quickly** without googling again and again.  
- To keep both **code + resources** in one place.  
- To expand gradually as I learn/implement more.  

---

## Status
ðŸš§ Work in progress â†’ more notes and models will be added.  
